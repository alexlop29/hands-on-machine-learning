{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "366fcf32-6a02-41ae-8bc1-7664459acdb1",
   "metadata": {},
   "source": [
    "### Linear Regressions\n",
    "\n",
    "> Linear regression is a supervised machine-learning algorithm.\n",
    "> ...\n",
    "> Supervised machine-learning algorithms learn from the labeled datasets and map the data points to the most optimized linear functions.\n",
    "> ...\n",
    "> Regression predicts the continuous output variables based on the independent input variable.\n",
    "> Example: the prediction of house prices based on different parameters like house age, distance from the main road, location, area, etc.\n",
    "\n",
    "https://www.geeksforgeeks.org/ml-linear-regression/\n",
    "\n",
    "> A linear model makes a prediction by simply computing a weighted sum of the input features, plus a constant called the bias term (also called the intercept term), as shown in Equation 4-1.\n",
    "\n",
    "hands-on-machine-learning\n",
    "\n",
    "Example: \n",
    "```\n",
    "life_satisfaction = Œ∏0 + Œ∏1 √ó GDP_per_capita\n",
    "This model is just a linear function of the input feature GDP_per_capita. Œ∏0 and Œ∏1 are the model‚Äôs parameters.\n",
    "```\n",
    "\n",
    "> The most common performance measure of a regression model is the root mean square error.\n",
    "\n",
    "hands-on-machine-learning\n",
    "\n",
    "> What Is Cost Function of Linear Regression?\n",
    "> Cost function measures the performance of a machine learning model for a data set.\n",
    "> Cost function quantifies the error between predicted and expected values and presents that error in the form of a single real number.\n",
    "\n",
    "https://builtin.com/machine-learning/cost-function\n",
    "\n",
    "\n",
    "#### Video References\n",
    "- [What is Linear Regression in Machine Learning ? Understand with Examples!](https://www.youtube.com/watch?v=nwD5U2WxTdk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09a17330-446d-4d88-888a-c7e5b8b7dcc5",
   "metadata": {},
   "source": [
    "> MSE measures the average squared difference between an observation‚Äôs actual and predicted values. The output is a single number representing the cost, or score, associated with our current set of weights. Our goal is to minimize MSE to improve the accuracy of our model.\n",
    "\n",
    "https://ml-cheatsheet.readthedocs.io/en/latest/linear_regression.html#:~:text=Cost%20function,-The%20prediction%20function&text=MSE%20measures%20the%20average%20squared,the%20accuracy%20of%20our%20model.\n",
    "\n",
    "> To find the value of Œ∏ that minimizes the MSE, there exists a closed-form solution‚Äîin other words, a mathematical equation that gives the result directly. This is called the Normal equation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00badad0-021a-4794-be8e-c2fa2bb041cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m 100\n",
      "X [[0.74908024]\n",
      " [1.90142861]\n",
      " [1.46398788]\n",
      " [1.19731697]\n",
      " [0.31203728]\n",
      " [0.31198904]\n",
      " [0.11616722]\n",
      " [1.73235229]\n",
      " [1.20223002]\n",
      " [1.41614516]]\n",
      "Y [[5.58520754]\n",
      " [7.50384988]\n",
      " [7.01973654]\n",
      " [4.40706502]\n",
      " [4.40440267]\n",
      " [4.98109065]\n",
      " [5.71022849]\n",
      " [6.94643436]\n",
      " [5.59596644]\n",
      " [6.33053327]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42) # make the code reproducible\n",
    "\"\"\"\n",
    "older syntax ?  - Numpy now recommends using a dedicated Generator instance\n",
    "See: https://numpy.org/doc/2.0/reference/random/generated/numpy.random.seed.html\n",
    "\n",
    "use case: https://stackoverflow.com/questions/21494489/what-does-numpy-random-seed0-do\n",
    "With the seed reset (every time), the same set of numbers will appear every time.\n",
    "If the random seed is not reset, different numbers appear with every invocation:\n",
    "\n",
    "\"Setting the seed for reproduce work\" means to initialize a random number generator\n",
    "with a specific value, ensuring that whenever you run your code, the same sequence of\n",
    "random numbers is generated, allowing you to precisely replicate your results and make\n",
    "your work reproducible\n",
    "Google AI\n",
    "\"\"\" \n",
    "\n",
    "m = 100 # num of instances\n",
    "X = 2 * np.random.rand(m, 1) # column vector\n",
    "Y = 4 + 2 * X + np.random.randn(m, 1) # column vector\n",
    "\n",
    "print(\"m\", m)\n",
    "print(\"X\", X[:10])\n",
    "print(\"Y\", Y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a66922a-533d-4198-aa74-1a206a1abae7",
   "metadata": {},
   "source": [
    "Now let‚Äôs compute ùõâ using the Normal equation. We will use the inv() function from NumPy‚Äôs linear algebra module (np.linalg) to compute the inverse of a matrix, and the dot() method for matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "918189a3-2c84-40be-8ff4-63534489322d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m 100\n",
      "X [[0.74908024]\n",
      " [1.90142861]\n",
      " [1.46398788]\n",
      " [1.19731697]\n",
      " [0.31203728]\n",
      " [0.31198904]\n",
      " [0.11616722]\n",
      " [1.73235229]\n",
      " [1.20223002]\n",
      " [1.41614516]]\n",
      "y [[5.58520754]\n",
      " [7.50384988]\n",
      " [7.01973654]\n",
      " [4.40706502]\n",
      " [4.40440267]\n",
      " [4.98109065]\n",
      " [5.71022849]\n",
      " [6.94643436]\n",
      " [5.59596644]\n",
      " [6.33053327]]\n",
      "X_b [[1.         0.74908024]\n",
      " [1.         1.90142861]\n",
      " [1.         1.46398788]\n",
      " [1.         1.19731697]\n",
      " [1.         0.31203728]\n",
      " [1.         0.31198904]\n",
      " [1.         0.11616722]\n",
      " [1.         1.73235229]\n",
      " [1.         1.20223002]\n",
      " [1.         1.41614516]]\n",
      "theta_best [[4.21509616]\n",
      " [1.77011339]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# new imports\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "\"\"\"\n",
    "sklearn.preprocessing.add_dummy_feature(X, value=1.0)\n",
    "Augment dataset with an additional dummy feature.\n",
    "This is useful for fitting an intercept term with implementations which cannot otherwise fit it directly.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.add_dummy_feature.html\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(42)\n",
    "m = 100\n",
    "X = 2 * np.random.rand(m ,1)\n",
    "y = 4 + 2 * X + np.random.randn(m, 1)\n",
    "\n",
    "\"\"\"\n",
    "Understanding the Linear Model\n",
    "In a linear regression setting, the relationship between X and Y is often modeled as:\n",
    "\n",
    "Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX + Œµ\n",
    "\n",
    "Where:\n",
    "Œ≤‚ÇÄ (4): The intercept, representing the value of Y when X = 0.\n",
    "Œ≤‚ÇÅ (2): The slope of the line, representing the rate of change of Y with respect to X.\n",
    "Œµ (random noise): Represents random variation or \"noise\" that is added to\n",
    "make the data more realistic.\n",
    "Chat GPT Example\n",
    "\"\"\"\n",
    "\n",
    "X_b = add_dummy_feature(X)\n",
    "\"\"\"\n",
    "Understand the purpose of X_b\n",
    "The function sklearn.preprocessing.add_dummy_feature adds a column of constant values (typically 1.0)\n",
    "to a feature matrix X. This dummy column is often used to account for the intercept term in a linear\n",
    "regression model.\n",
    "\n",
    "X= \n",
    "0.5\n",
    "1.2\n",
    "0.8\n",
    "\n",
    "X b\t=  \n",
    "1 0.5\n",
    "1 1.2\n",
    "1 0.8\n",
    "Chat GPT\n",
    "\"\"\"\n",
    "\n",
    "theta_best = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y\n",
    "\"\"\"\n",
    "numpy.linalg.inv\n",
    "Compute the inverse of a matrix\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.linalg.inv.html\n",
    "\n",
    "Matrix: a data structure composed of rows and columns\n",
    "https://www.lenovo.com ‚Ä∫ outletus ‚Ä∫ glossary ‚Ä∫ matrix\n",
    "\"\"\"\n",
    "\n",
    "print(\"m\", m)\n",
    "print(\"X\", X[:10])\n",
    "print(\"y\", y[:10])\n",
    "print(\"X_b\", X_b[:10])\n",
    "print(\"theta_best\", theta_best[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5305bdf1-d014-45a0-b89f-2fb21726021c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m 100\n",
      "X [[0.74908024]\n",
      " [1.90142861]\n",
      " [1.46398788]\n",
      " [1.19731697]\n",
      " [0.31203728]\n",
      " [0.31198904]\n",
      " [0.11616722]\n",
      " [1.73235229]\n",
      " [1.20223002]\n",
      " [1.41614516]]\n",
      "y [[5.58520754]\n",
      " [7.50384988]\n",
      " [7.01973654]\n",
      " [4.40706502]\n",
      " [4.40440267]\n",
      " [4.98109065]\n",
      " [5.71022849]\n",
      " [6.94643436]\n",
      " [5.59596644]\n",
      " [6.33053327]]\n",
      "X_b [[1.         0.74908024]\n",
      " [1.         1.90142861]\n",
      " [1.         1.46398788]\n",
      " [1.         1.19731697]\n",
      " [1.         0.31203728]\n",
      " [1.         0.31198904]\n",
      " [1.         0.11616722]\n",
      " [1.         1.73235229]\n",
      " [1.         1.20223002]\n",
      " [1.         1.41614516]]\n",
      "theta_best [[4.21509616]\n",
      " [1.77011339]]\n",
      "y_predict [[4.21509616]\n",
      " [7.75532293]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# new imports\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "\"\"\"\n",
    "sklearn.preprocessing.add_dummy_feature(X, value=1.0)\n",
    "Augment dataset with an additional dummy feature.\n",
    "This is useful for fitting an intercept term with implementations which cannot otherwise fit it directly.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.add_dummy_feature.html\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(42)\n",
    "m = 100\n",
    "X = 2 * np.random.rand(m ,1)\n",
    "y = 4 + 2 * X + np.random.randn(m, 1)\n",
    "\n",
    "\"\"\"\n",
    "Understanding the Linear Model\n",
    "In a linear regression setting, the relationship between X and Y is often modeled as:\n",
    "\n",
    "Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX + Œµ\n",
    "\n",
    "Where:\n",
    "Œ≤‚ÇÄ (4): The intercept, representing the value of Y when X = 0.\n",
    "Œ≤‚ÇÅ (2): The slope of the line, representing the rate of change of Y with respect to X.\n",
    "Œµ (random noise): Represents random variation or \"noise\" that is added to\n",
    "make the data more realistic.\n",
    "Chat GPT Example\n",
    "\"\"\"\n",
    "\n",
    "X_b = add_dummy_feature(X)\n",
    "\"\"\"\n",
    "Understand the purpose of X_b\n",
    "The function sklearn.preprocessing.add_dummy_feature adds a column of constant values (typically 1.0)\n",
    "to a feature matrix X. This dummy column is often used to account for the intercept term in a linear\n",
    "regression model.\n",
    "\n",
    "X= \n",
    "0.5\n",
    "1.2\n",
    "0.8\n",
    "\n",
    "X b\t=  \n",
    "1 0.5\n",
    "1 1.2\n",
    "1 0.8\n",
    "Chat GPT\n",
    "\"\"\"\n",
    "\n",
    "theta_best = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y\n",
    "\"\"\"\n",
    "numpy.linalg.inv\n",
    "Compute the inverse of a matrix\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.linalg.inv.html\n",
    "\n",
    "Matrix: a data structure composed of rows and columns\n",
    "https://www.lenovo.com ‚Ä∫ outletus ‚Ä∫ glossary ‚Ä∫ matrix\n",
    "\"\"\"\n",
    "\n",
    "print(\"m\", m)\n",
    "print(\"X\", X[:10])\n",
    "print(\"y\", y[:10])\n",
    "print(\"X_b\", X_b[:10])\n",
    "print(\"theta_best\", theta_best[:10])\n",
    "\n",
    "X_new = np.array([[0],[2]])\n",
    "X_new_b = add_dummy_feature(X_new)\n",
    "y_predict = X_new_b @ theta_best\n",
    "print(\"y_predict\", y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de1813c6-1f5e-46d0-aa9c-69458784f517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m 100\n",
      "X [[0.74908024]\n",
      " [1.90142861]\n",
      " [1.46398788]\n",
      " [1.19731697]\n",
      " [0.31203728]\n",
      " [0.31198904]\n",
      " [0.11616722]\n",
      " [1.73235229]\n",
      " [1.20223002]\n",
      " [1.41614516]]\n",
      "y [[5.58520754]\n",
      " [7.50384988]\n",
      " [7.01973654]\n",
      " [4.40706502]\n",
      " [4.40440267]\n",
      " [4.98109065]\n",
      " [5.71022849]\n",
      " [6.94643436]\n",
      " [5.59596644]\n",
      " [6.33053327]]\n",
      "X_b [[1.         0.74908024]\n",
      " [1.         1.90142861]\n",
      " [1.         1.46398788]\n",
      " [1.         1.19731697]\n",
      " [1.         0.31203728]\n",
      " [1.         0.31198904]\n",
      " [1.         0.11616722]\n",
      " [1.         1.73235229]\n",
      " [1.         1.20223002]\n",
      " [1.         1.41614516]]\n",
      "theta_best [[4.21509616]\n",
      " [1.77011339]]\n",
      "y_predict [[4.21509616]\n",
      " [7.75532293]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import add_dummy_feature\n",
    "\"\"\"\n",
    "sklearn.preprocessing.add_dummy_feature(X, value=1.0)\n",
    "Augment dataset with an additional dummy feature.\n",
    "This is useful for fitting an intercept term with implementations which cannot otherwise fit it directly.\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.add_dummy_feature.html\n",
    "\"\"\"\n",
    "\n",
    "# new import \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "m = 100\n",
    "X = 2 * np.random.rand(m ,1)\n",
    "y = 4 + 2 * X + np.random.randn(m, 1)\n",
    "\n",
    "\"\"\"\n",
    "Understanding the Linear Model\n",
    "In a linear regression setting, the relationship between X and Y is often modeled as:\n",
    "\n",
    "Y = Œ≤‚ÇÄ + Œ≤‚ÇÅX + Œµ\n",
    "\n",
    "Where:\n",
    "Œ≤‚ÇÄ (4): The intercept, representing the value of Y when X = 0.\n",
    "Œ≤‚ÇÅ (2): The slope of the line, representing the rate of change of Y with respect to X.\n",
    "Œµ (random noise): Represents random variation or \"noise\" that is added to\n",
    "make the data more realistic.\n",
    "Chat GPT Example\n",
    "\"\"\"\n",
    "\n",
    "X_b = add_dummy_feature(X)\n",
    "\"\"\"\n",
    "Understand the purpose of X_b\n",
    "The function sklearn.preprocessing.add_dummy_feature adds a column of constant values (typically 1.0)\n",
    "to a feature matrix X. This dummy column is often used to account for the intercept term in a linear\n",
    "regression model.\n",
    "\n",
    "X= \n",
    "0.5\n",
    "1.2\n",
    "0.8\n",
    "\n",
    "X b\t=  \n",
    "1 0.5\n",
    "1 1.2\n",
    "1 0.8\n",
    "Chat GPT\n",
    "\"\"\"\n",
    "\n",
    "theta_best = np.linalg.inv(X_b.T @ X_b) @ X_b.T @ y\n",
    "\"\"\"\n",
    "numpy.linalg.inv\n",
    "Compute the inverse of a matrix\n",
    "https://numpy.org/doc/stable/reference/generated/numpy.linalg.inv.html\n",
    "\n",
    "Matrix: a data structure composed of rows and columns\n",
    "https://www.lenovo.com ‚Ä∫ outletus ‚Ä∫ glossary ‚Ä∫ matrix\n",
    "\"\"\"\n",
    "\n",
    "print(\"m\", m)\n",
    "print(\"X\", X[:10])\n",
    "print(\"y\", y[:10])\n",
    "print(\"X_b\", X_b[:10])\n",
    "print(\"theta_best\", theta_best[:10])\n",
    "\n",
    "X_new = np.array([[0],[2]])\n",
    "X_new_b = add_dummy_feature(X_new)\n",
    "y_predict = X_new_b @ theta_best\n",
    "print(\"y_predict\", y_predict)\n",
    "\n",
    "# plot\n",
    "plt.plot(X_new, y_predict, \"r-\", label=\"Predictions\")\n",
    "plt.plot(X, y, \"b.\")\n",
    "[...]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acf79ad2-fa89-4480-9207-92c744f1891b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lin_reg intercept [4.21509616]\n",
      "lin_reg.coef_ [[1.77011339]]\n",
      "predict [[4.21509616]\n",
      " [7.75532293]]\n"
     ]
    }
   ],
   "source": [
    "# Perform linear regression using Sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "\n",
    "# Seed data\n",
    "np.random.seed(42)\n",
    "m = 100\n",
    "X = 2 * np.random.rand(m ,1)\n",
    "y = 4 + 2 * X + np.random.randn(m, 1)\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X, y)\n",
    "\n",
    "print(\"lin_reg intercept\", lin_reg.intercept_)\n",
    "print(\"lin_reg.coef_\", lin_reg.coef_)\n",
    "\n",
    "# predict\n",
    "X_new = np.array([[0],[2]])\n",
    "print(\"predict\", lin_reg.predict(X_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6caea6-5a52-40dd-ad3e-30564b145c4a",
   "metadata": {},
   "source": [
    "> This function computes ùõâ, where is the pseudoinverse of X (specifically, the Moore‚ÄìPenrose inverse). You can use np.linalg.pinv() to compute the pseudoinverse directly.\n",
    "\n",
    "> This approach is more efficient than computing the Normal equation, plus it handles edge cases nicely: indeed, the Normal equation may not work if the matrix X‚ä∫X is not invertible (i.e., singular), such as if m < n or if some features are redundant, but the pseudoinverse is always defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af51fc01-6c33-48fd-b2ae-f3ebc2dd5af7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pseudoinverse [[4.21509616]\n",
      " [1.77011339]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import add_dummy_feature\n",
    "import numpy as np\n",
    "\n",
    "# Seed data\n",
    "np.random.seed(42)\n",
    "m = 100\n",
    "X = 2 * np.random.rand(m ,1)\n",
    "y = 4 + 2 * X + np.random.randn(m, 1)\n",
    "\n",
    "# Add dummy feature\n",
    "X_b = add_dummy_feature(X)\n",
    "\n",
    "print(\"pseudoinverse\", np.linalg.pinv(X_b) @ y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70aa6e1-9994-4a65-9427-e4465dcf1082",
   "metadata": {},
   "source": [
    "# Computational Complexity\n",
    "\n",
    "> The Normal equation computes the inverse of X‚ä∫ X...\n",
    ">  if you double the number of features, you multiply the computation time by roughly 22.4 = 5.3 to 23 = 8.\n",
    "\n",
    "> The SVD approach used by Scikit-Learn‚Äôs LinearRegression class is about O(n2). If you double the number of features, you multiply the computation time by roughly 4.\n",
    "\n",
    "Both the Normal equation and the SVD approach get very slow when the number of features grows large.\n",
    "\n",
    "> Once you have trained your linear regression model (using the Normal equation or any other algorithm), predictions are very fast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0160defd-0a35-41bd-b99d-b3f1c5eb002e",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "> Gradient descent is a generic optimization algorithm capable of finding optimal solutions to a wide range of problems. The general idea of gradient descent is to tweak parameters iteratively in order to minimize a cost function.\n",
    "\n",
    "Example:\n",
    "> Suppose you are lost in the mountains in a dense fog, and you can only feel the slope of the ground below your feet. A good strategy to get to the bottom of the valley quickly is to go downhill in the direction of the steepest slope. This is exactly what gradient descent does.\n",
    "\n",
    "> An important parameter in gradient descent is the size of the steps, determined by the learning rate hyperparameter. If the learning rate is too small, then the algorithm will have to go through many iterations to converge, which will take a long time\n",
    "> if the learning rate is too high, you might jump across the valley and end up on the other side\n",
    "\n",
    "> Additionally, not all cost functions look like nice, regular bowls. There may be holes, ridges, plateaus, and all sorts of irregular terrain, making convergence to the minimum difficult.\n",
    "\n",
    "> This diagram also illustrates the fact that training a model means searching for a combination of model parameters that minimizes a cost function (over the training set)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8dd721-70ff-4121-b08e-93cabda5d4cf",
   "metadata": {},
   "source": [
    "# Batch Gradient Descent\n",
    "\n",
    "> To implement gradient descent, you need to compute the gradient of the cost function with regard to each model parameter Œ∏j. In other words, you need to calculate how much the cost function will change if you change Œ∏j just a little bit. This is called a partial derivative.\n",
    "\n",
    "> Instead of computing these partial derivatives individually, you can use Equation 4-6 to compute them all in one go.\n",
    "\n",
    "> This is why the algorithm is called batch gradient descent: it uses the whole batch of training data at every step (actually, full gradient descent would probably be a better name). As a result, it is terribly slow on very large training sets (we will look at some much faster gradient descent algorithms shortly).\n",
    "\n",
    "> To find a good learning rate, you can use grid search (see Chapter¬†2).\n",
    "\n",
    "> To find the optimal learning rate for a linear regression model using grid search, you essentially create a range of different learning rate values, train the model with each value, and then use cross-validation to identify the learning rate that produces the best performance on your validation set, effectively \"searching\" across a grid of potential learning rates to find the best one.\n",
    "Google AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b63ed338-ca52-47ff-9c8a-ce08ebc0bcb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theta [[4.21509616]\n",
      " [1.77011339]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import add_dummy_feature\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Each time a dataset passes through an algorithm, it is said to have completed an epoch.\n",
    "Therefore, Epoch, in machine learning, refers to the one entire passing of training data\n",
    "through the algorithm.\n",
    "https://www.simplilearn.com/tutorials/machine-learning-tutorial/what-is-epoch-in-machine-learning#:~:text=Each%20time%20a%20dataset%20passes,training%20data%20through%20the%20algorithm.\n",
    "\"\"\"\n",
    "\n",
    "# Seed data\n",
    "np.random.seed(42)\n",
    "m = 100\n",
    "X = 2 * np.random.rand(m ,1)\n",
    "y = 4 + 2 * X + np.random.randn(m, 1)\n",
    "\n",
    "# Add dummy feature\n",
    "X_b = add_dummy_feature(X)\n",
    "\n",
    "eta = 0.1 # learning rate\n",
    "n_epochs = 1000\n",
    "m = len(X_b) # number of instances\n",
    "\n",
    "np.random.seed(42)\n",
    "theta = np.random.randn(2,1) # randomly initialized model parameters\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    gradients = 2 / m * X_b.T @ (X_b @ theta - y)\n",
    "    theta = theta - eta * gradients\n",
    "\n",
    "print(\"theta\", theta) # matches the normal equation exactly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "555ee734-7126-4eb8-9d35-462326ee8b28",
   "metadata": {},
   "source": [
    "> You may wonder how to set the number of epochs.\n",
    "\n",
    "> A simple solution is to set a very large number of epochs but to interrupt the algorithm when the gradient vector becomes tiny‚Äîthat is, when its norm becomes smaller than a tiny number œµ (called the tolerance)‚Äîbecause this happens when gradient descent has (almost) reached the minimum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1b371-72ae-48d0-8854-450ef958ab2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becb0ffe-05e1-43f1-8dda-55340492b6b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
